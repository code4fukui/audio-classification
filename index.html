<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width"><link rel="icon" href="data:">
<title>音声識別 by MediaPipe</title>
</head><body>
<h1>音声識別 by MediaPipe</h1>

<main>
<button id=btn disabled></button>
<div id="divresult"></div>
</main>

<a href=https://github.com/code4fukui/audio-classification>src on GitHub</a>

<script type="module">
// Copyright 2023 The MediaPipe Authors.

// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at

//      http://www.apache.org/licenses/LICENSE-2.0

// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import audio from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-audio@0.10.0";
import { CSV } from "https://js.sabae.cc/CSV.js";

const { AudioClassifier, AudioClassifierResult, FilesetResolver } = audio;

const labels = await CSV.fetchJSON("./yammnet_label.csv");
const en2ja = (s) => {
  const label = labels.find(i => i.yammnet_label == s);
  if (label) return label.yammnet_label_ja;
  return s;
};

const createAudioClassifier = async () => {
  const audio = await FilesetResolver.forAudioTasks(
    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-audio@0.10.0/wasm"
  );
  const modelAssetPath = "https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.tflite";
  const audioClassifier = await AudioClassifier.createFromOptions(audio, {
    baseOptions: { modelAssetPath }
  });
  btn.disabled = false;
  return audioClassifier;
};
const audioClassifier = await createAudioClassifier();

let audioCtx;

const LABEL_START = "音声識別開始";
const LABEL_STOP = "音声識別停止";
btn.textContent = LABEL_START;

const runStreamingAudioClassification = async () => {
  const output = divresult;
  const constraints = { audio: true };
  let stream;

  try {
    stream = await navigator.mediaDevices.getUserMedia(constraints);
  } catch (err) {
    console.log("The following error occured: " + err);
    alert("getUserMedia not supported on your browser");
    return;
  }

  if (!audioCtx) {
    audioCtx = new AudioContext({ sampleRate: 16000 });
  } else if (audioCtx.state === "running") {
    await audioCtx.suspend();
    btn.textContent = LABEL_START;
    return;
  }

  // resumes AudioContext if has been suspended
  await audioCtx.resume();

  btn.textConten = LABEL_STOP;
  
  const source = audioCtx.createMediaStreamSource(stream);
  const scriptNode = audioCtx.createScriptProcessor(16384, 1, 1);

  scriptNode.onaudioprocess = function (audioProcessingEvent) {
    const inputBuffer = audioProcessingEvent.inputBuffer;
    const inputData = inputBuffer.getChannelData(0);

    // Classify the audio
    const result = audioClassifier.classify(inputData);
    const categories = result[0].classifications[0].categories;

    // Display results
    const scoreth = .10;
    const res = [];
    for (let i = 0; i < categories.length; i++) {
      const c = categories[i];
      if (c.score >= scoreth) {
        res.push(`${en2ja(c.categoryName)} (${(c.score * 100).toFixed(1)}%)`);
      }
    }
    output.innerText = res.join("\n");
  };

  source.connect(scriptNode);
  scriptNode.connect(audioCtx.destination);
};

btn.onclick = async () => await runStreamingAudioClassification();
</script>

<style>
body {
  font-family: sans-serif;
  text-align: center;
}
main {
  margin: 1vh;
  font-size: 4vw;
}
main > * {
  margin: .5vh;
}
</style>
